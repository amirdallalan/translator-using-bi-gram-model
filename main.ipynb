{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translator using Bi-gram Model\n",
    "\n",
    "## Prepare everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Amirhosein\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Amirhosein\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\Amirhosein\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Amirhosein\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hazm\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_translator import GoogleTranslator\n",
    "from nltk.corpus import reuters, stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import itertools\n",
    "\n",
    "from LoadData import LoadData\n",
    "from WordCounts import WordCounts\n",
    "from BigramProbability import BigramProbability\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('reuters')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\n",
      "  Mounting trade friction between the\n",
      "  U.S. And Japan has raised fears among many of Asia's exporting\n",
      "  nations that the row could inflict far-reaching economic\n",
      "  damage, businessmen and officials said.\n",
      "      They told Reuter correspondents in Asian capitals a U.S.\n",
      "  Move against Japan might boost protectionist sentiment in the\n",
      "  U.S. And lead to curbs on American imports of their products.\n",
      "      But some exporters said that while the conflict would hurt\n",
      "  them in the long-run, in the short-term Tokyo's loss might be\n",
      "  their gain.\n",
      "      The U.S. Has said it will impose 300 mln dlrs of tariffs on\n",
      "  imports of Japanese electronics goods on April 17, in\n",
      "  retaliation for Japan's alleged failure to stick to a pact not\n",
      "  to sell semiconductors on world markets at below cost.\n",
      "      Unofficial Japanese estimates put the impact of the tariffs\n",
      "  at 10 billion dlrs and spokesmen for major electronics firms\n",
      "  said they would virtually halt exports of products hit by the\n",
      "  new taxes.\n",
      "      \"We wouldn't be able to do business,\" said a spokesman for\n",
      "  leading Japanese electronics firm Matsushita Electric\n",
      "  Industrial Co Ltd &lt;MC.T>.\n",
      "      \"If the tariffs remain in place for any length of time\n",
      "  beyond a few months it will mean the complete erosion of\n",
      "  exports (of goods subject to tariffs) to the U.S.,\" said Tom\n",
      "  Murtha, a stock analyst at the Tokyo office of broker &lt;James\n",
      "  Capel and Co>.\n",
      "      In Taiwan, businessmen and officials are also worried.\n",
      "      \"We are aware of the seriousness of the U.S. Threat against\n",
      "  Japan because it serves as a warning to us,\" said a senior\n",
      "  Taiwanese trade official who asked not to be named.\n",
      "      Taiwan had a trade trade surplus of 15.6 billion dlrs last\n",
      "  year, 95 pct of it with the U.S.\n",
      "      The surplus helped swell Taiwan's foreign exchange reserves\n",
      "  to 53 billion dlrs, among the world's largest.\n",
      "      \"We must quickly open our markets, remove trade barriers and\n",
      "  cut import tariffs to allow imports of U.S. Products, if we\n",
      "  want to defuse problems from possible U.S. Retaliation,\" said\n",
      "  Paul Sheen, chairman of textile exporters &lt;Taiwan Safe Group>.\n",
      "      A senior official of South Korea's trade promotion\n",
      "  association said the trade dispute between the U.S. And Japan\n",
      "  might also lead to pressure on South Korea, whose chief exports\n",
      "  are similar to those of Japan.\n",
      "      Last year South Korea had a trade surplus of 7.1 billion\n",
      "  dlrs with the U.S., Up from 4.9 billion dlrs in 1985.\n",
      "      In Malaysia, trade officers and businessmen said tough\n",
      "  curbs against Japan might allow hard-hit producers of\n",
      "  semiconductors in third countries to expand their sales to the\n",
      "  U.S.\n",
      "      In Hong Kong, where newspapers have alleged Japan has been\n",
      "  selling below-cost semiconductors, some electronics\n",
      "  manufacturers share that view. But other businessmen said such\n",
      "  a short-term commercial advantage would be outweighed by\n",
      "  further U.S. Pressure to block imports.\n",
      "      \"That is a very short-term view,\" said Lawrence Mills,\n",
      "  director-general of the Federation of Hong Kong Industry.\n",
      "      \"If the whole purpose is to prevent imports, one day it will\n",
      "  be extended to other sources. Much more serious for Hong Kong\n",
      "  is the disadvantage of action restraining trade,\" he said.\n",
      "      The U.S. Last year was Hong Kong's biggest export market,\n",
      "  accounting for over 30 pct of domestically produced exports.\n",
      "      The Australian government is awaiting the outcome of trade\n",
      "  talks between the U.S. And Japan with interest and concern,\n",
      "  Industry Minister John Button said in Canberra last Friday.\n",
      "      \"This kind of deterioration in trade relations between two\n",
      "  countries which are major trading partners of ours is a very\n",
      "  serious matter,\" Button said.\n",
      "      He said Australia's concerns centred on coal and beef,\n",
      "  Australia's two largest exports to Japan and also significant\n",
      "  U.S. Exports to that country.\n",
      "      Meanwhile U.S.-Japanese diplomatic manoeuvres to solve the\n",
      "  trade stand-off continue.\n",
      "      Japan's ruling Liberal Democratic Party yesterday outlined\n",
      "  a package of economic measures to boost the Japanese economy.\n",
      "      The measures proposed include a large supplementary budget\n",
      "  and record public works spending in the first half of the\n",
      "  financial year.\n",
      "      They also call for stepped-up spending as an emergency\n",
      "  measure to stimulate the economy despite Prime Minister\n",
      "  Yasuhiro Nakasone's avowed fiscal reform program.\n",
      "      Deputy U.S. Trade Representative Michael Smith and Makoto\n",
      "  Kuroda, Japan's deputy minister of International Trade and\n",
      "  Industry (MITI), are due to meet in Washington this week in an\n",
      "  effort to end the dispute.\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_id in reuters.fileids():\n",
    "  txt = reuters.open(file_id).read()\n",
    "  print(txt)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of doc: 983789 word \n",
      "first 10 word:\n",
      " ['<START>', 'asian', 'export', 'fear', 'damag', 'japan', 'rift', 'mount', 'trade', 'friction']\n"
     ]
    }
   ],
   "source": [
    "doc = LoadData()\n",
    "\n",
    "print(\"length of doc:\",len(doc),\"word \")\n",
    "print(\"first 10 word:\\n\",doc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: \t\t\t  count:\n",
      "('<START>', 'asian') \t\t 4\n",
      "('asian', 'export') \t\t 1\n",
      "('export', 'fear') \t\t 3\n",
      "('fear', 'damag') \t\t 1\n",
      "('damag', 'japan') \t\t 1\n",
      "('japan', 'rift') \t\t 1\n"
     ]
    }
   ],
   "source": [
    "swc, pwc = WordCounts(doc)\n",
    "\n",
    "print(\"words:\", \"\\t\\t\\t  count:\")\n",
    "\n",
    "for idx, pair in enumerate(pwc):\n",
    "    print(pair,\"\\t\\t\",pwc[pair])\n",
    "    if idx == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram: \t\t  probability:\n",
      "('<START>', 'asian') \t\t 7.31047591198187e-05\n",
      "('asian', 'export') \t\t 0.015384615384615385\n",
      "('export', 'fear') \t\t 0.0010893246187363835\n",
      "('fear', 'damag') \t\t 0.006211180124223602\n",
      "('damag', 'japan') \t\t 0.0038022813688212928\n",
      "('japan', 'rift') \t\t 0.0005291005291005291\n"
     ]
    }
   ],
   "source": [
    "unigram_prob, bigram_prob = BigramProbability(swc, pwc)\n",
    "\n",
    "print(\"bigram:\", \"\\t\\t  probability:\")\n",
    "\n",
    "for idx, pair in enumerate(bigram_prob):\n",
    "    print(pair,\"\\t\\t\",bigram_prob[pair])\n",
    "    if idx == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate likelihood matrix\n",
    "likelyhood = {}\n",
    "\n",
    "for (a, _) in swc.items():\n",
    "  for (b, _) in swc.items():\n",
    "    prob_a = unigram_prob.get(a)\n",
    "    prob_ab = bigram_prob.get((a,b),0)\n",
    "    likelyhood[(a, b)] = 0 if prob_a == 0 else prob_ab / prob_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram: \t\t likelyhood:\n",
      "('<START>', '<START>') \t\t 0.0\n",
      "('<START>', 'asian') \t\t 0.0013144173161365475\n",
      "('<START>', 'export') \t\t 0.06473505281972496\n",
      "('<START>', 'fear') \t\t 0.004271856277443779\n",
      "('<START>', 'damag') \t\t 0.002628834632273095\n",
      "('<START>', 'japan') \t\t 0.10219594632961655\n"
     ]
    }
   ],
   "source": [
    "print(\"bigram:\", \"\\t\\t likelyhood:\")\n",
    "\n",
    "for idx, pair in enumerate(likelyhood):\n",
    "    print(pair,\"\\t\\t\",likelyhood[pair])\n",
    "    if idx == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"پردازش زبان طبیعی رشته‌ای از هوش مصنوعی است.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['پردازش', 'زبان', 'طبیعی', 'رشته\\u200cای', 'از', 'هوش', 'مصنوعی', 'است', '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = hazm.Normalizer()\n",
    "normalized_words = normalizer.normalize(input)\n",
    "input_words = hazm.word_tokenize(normalized_words)\n",
    "input_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<START>',\n",
       " 'process',\n",
       " 'languag',\n",
       " 'natur',\n",
       " 'string',\n",
       " 'from',\n",
       " 'intellig',\n",
       " 'artifici',\n",
       " 'is',\n",
       " '<END>']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = GoogleTranslator(source='fa', target='en')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "eng_tokens = []\n",
    "for x in input_words:\n",
    "  r = translator.translate(x)\n",
    "  if r is None:\n",
    "    continue\n",
    "  eng_tokens.append(r)\n",
    "\n",
    "tokens = ['<START>']\n",
    "for w in eng_tokens:\n",
    "  s = stemmer.stem(w)\n",
    "  tokens.extend(nltk.word_tokenize(s))\n",
    "tokens.append('<END>')\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileids = reuters.fileids()\n",
    "uniq_tokens = set()\n",
    "\n",
    "for file_id in fileids[:10]:\n",
    "  for w in reuters.words(file_id):\n",
    "    s = stemmer.stem(w)\n",
    "    uniq_tokens.update(nltk.word_tokenize(s))\n",
    "\n",
    "next_idx = 2\n",
    "reverse_idx = {'<START>': 0, '<END>': 1}\n",
    "\n",
    "for token in uniq_tokens:\n",
    "  reverse_idx[token] = next_idx\n",
    "  next_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> process languag natur string from intellig artifici is <END>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutations = list(itertools.permutations(tokens))\n",
    "probs = np.zeros(len(permutations))\n",
    "\n",
    "for j, permute in enumerate(permutations):\n",
    "  total_prob = 1.0\n",
    "  for i, w in enumerate(permute):\n",
    "    if i == len(permute) - 1:\n",
    "      break\n",
    "    x_w_idx = reverse_idx.get(w)\n",
    "    if not x_w_idx:\n",
    "      continue\n",
    "    x_n_idx = reverse_idx.get(permute[i + 1])\n",
    "    if not x_n_idx:\n",
    "      continue\n",
    "    total_prob *= likelyhood.get((x_w_idx, x_n_idx), 0)\n",
    "  probs[j] = total_prob\n",
    "\n",
    "z = np.argmax(probs)\n",
    "' '.join(permutations[z])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
